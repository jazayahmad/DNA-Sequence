{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An excerpt from keras' source code example of classifying the\n",
    "cifar-10 dataset.\n",
    "\n",
    "Copied the initial part here to play around and try and get a handle\n",
    "on concepts like:\n",
    "    - input image dimensionality\n",
    "    - input image depth (i.e. note the 3 color channels in rgb images)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 200\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print('shape of an individual example: ',X_train[0].shape)\n",
    "\n",
    "# above print statements show:\n",
    "# shape: (60000, 3, 32, 32)\n",
    "# i.e. input is an array of 60,000 examples\n",
    "# each example has 3 subarrays (i.e. depth = 3) - corresponding to R, G, and B\n",
    "# each of the R, G, B subarrays is a 32x32 matrix representing the image\n",
    "#   from the perspective of that channel\n",
    "# contrastingly, note how greyscale images have only one channel\n",
    "# - hence a similar dataset for them would be (60000, 32, 32)\n",
    "# - you'd have to add a 1 to mark depth, thus converting to (60000, 1, 32, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
